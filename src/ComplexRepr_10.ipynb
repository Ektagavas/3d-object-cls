{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComplexRepresentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lx38cpNh88l",
        "colab_type": "text"
      },
      "source": [
        "##  Complex representation model with ModelNet10 dataset and VoxNet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caqDk6Tgh2go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision import transforms, utils\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.ndimage import rotate\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "import imp\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import argparse\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN2Ezhmu-tvH",
        "colab_type": "code",
        "outputId": "cfbff225-648a-454a-cf1a-91a28a1053a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install mahotas\n",
        "import mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.6/dist-packages (1.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCHwb5so-GJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelNetDataset(Dataset):\n",
        "    \"\"\"ModelNet10 dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, data_file, label_file, transform=None):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          data_file (string): Path to the npz file with annotations.\n",
        "          transform (callable, optional): Optional transform to be applied\n",
        "              on a sample.\n",
        "      \"\"\"\n",
        "      self.classes = classes\n",
        "      self.transform = transform\n",
        "\n",
        "      data = np.load(data_file)\n",
        "      labels = np.load(label_file)\n",
        "      self.X, self.Y = shuffle(data, labels)\n",
        "      self.nsamples = len(self.X)   \n",
        "\n",
        "    def __len__(self):\n",
        "      return self.nsamples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      x = self.X[idx]\n",
        "      y = self.Y[idx]\n",
        "      if self.transform:\n",
        "          x, y = self.transform((x,y))\n",
        "      return (x, y)\n",
        "\n",
        "    def show_voxelgrid(self, sample):\n",
        "      \"\"\"Show 3D voxel\"\"\"\n",
        "      X, Y = sample\n",
        "      ax.voxels(X, edgecolor=\"k\")\n",
        "      # plt.pause(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5RyqONv_v1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class toComplexRepr(object):\n",
        "  def __init__(self):\n",
        "    self.MAX_DISTANCE = float(\"inf\")\n",
        "\n",
        "  def normalize(self, X):\n",
        "    if(np.min(X)<np.max(X)):\n",
        "       X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
        "    return X\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    X, label = sample\n",
        "    dmap = mahotas.distance(1-X)    \n",
        "    dmap = self.normalize(dmap)\n",
        "    if np.isnan(dmap).any() == True:\n",
        "      print('NAN detected..............')\n",
        "    return (dmap, label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6C1oyap-PVA",
        "colab_type": "code",
        "outputId": "a6ba83bb-c3d2-4315-a4c7-47cb48443217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "modelnet_dataset = ModelNetDataset(data_file='drive/My Drive/Dataset/X_train.npy',\n",
        "                                    label_file='drive/My Drive/Dataset/y_train.npy')\n",
        "\n",
        "fig = plt.figure(figsize=(17, 7))\n",
        "\n",
        "for i in range(len(modelnet_dataset)):\n",
        "  sample = modelnet_dataset[i]\n",
        "\n",
        "  print(i, sample[0].shape, sample[1])\n",
        "\n",
        "  ax = fig.add_subplot(1, 4, i + 1, projection='3d')\n",
        "  ax.set_title('Sample #{0}, GT: {1}'.format(i, classes[sample[1]]))\n",
        "  # ax.axis('off')\n",
        "  modelnet_dataset.show_voxelgrid(sample)\n",
        "\n",
        "  if i == 3:\n",
        "      plt.show()\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (32, 32, 32) 5\n",
            "1 (32, 32, 32) 7\n",
            "2 (32, 32, 32) 0\n",
            "3 (32, 32, 32) 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzdItXUM9HJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VoxNet(torch.nn.Module):   \n",
        "\n",
        "    def __init__(self, num_classes=10, input_shape=(32,32,32)):\n",
        "\n",
        "        super(VoxNet, self).__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.cnn_layers = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.LeakyReLU(0.1)),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.LeakyReLU(0.1)),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.4))\n",
        "        ]))\n",
        "\n",
        "        x = self.cnn_layers(torch.autograd.Variable(torch.rand((1, 1) + self.input_shape)))\n",
        "        fc1_in = 1\n",
        "        for n in x.size()[1:]:\n",
        "            fc1_in *= n\n",
        "\n",
        "        self.linear_layers = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(fc1_in, 128)),\n",
        "            ('relu1', torch.nn.LeakyReLU(0.1)),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, num_classes))\n",
        "        ]))\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "\n",
        "        return x       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk0J19ncxxi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(loader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    num_batch = len(loader)\n",
        "    batch_size = loader.batch_size\n",
        "    total = torch.FloatTensor([0])\n",
        "    correct = torch.FloatTensor([0])\n",
        "    total_loss = 0.\n",
        "    n = 0\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(loader):\n",
        "        #inputs = torch.from_numpy(inputs)\n",
        "        # inputs = inputs.type(torch.DoubleTensor)\n",
        "        # targets = targets.type(torch.DoubleTensor)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs = inputs.reshape((-1, 1, 32, 32, 32))\n",
        "        targets = targets.reshape(-1)\n",
        "        inputs, targets = shuffle(inputs, targets)\n",
        "        # print(inputs)\n",
        "        #in 0.4.0 variable and tensor are merged\n",
        "        #inputs, targets = Variable(inputs), Variable(targets)\n",
        "\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        # compute output\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, targets.long())\n",
        "        \n",
        "        # loss = F.nll_loss(outputs, targets.long())\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        tl = loss.item()\n",
        "        n += 1\n",
        "        _, predicted = torch.max(outputs.detach(), 1)\n",
        "        # predicted = outputs.max(1, keepdim=True)[1]\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).cpu().sum()\n",
        "\n",
        "         # compute gradient and do SGD step\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        log_iter = 100\n",
        "        if (i + 1) % log_iter == 0:\n",
        "            print(\"\\tIter [%d/%d] Loss: %.4f\" % (i + 1, num_batch, tl/log_iter))\n",
        "            tl = 0.\n",
        "    train_acc = 100.0 * correct.item() / total.item()\n",
        "    train_loss = total_loss / n\n",
        "    print(\"Train Accuracy %.2f\" % (train_acc))\n",
        "    return train_acc, train_loss\n",
        "\n",
        "\n",
        "def test_model(loader, model, criterion, optimizer, device):\n",
        "\n",
        "    total = torch.LongTensor([0])\n",
        "    correct = torch.LongTensor([0])\n",
        "\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            inputs = inputs.reshape((-1, 1, 32, 32, 32))\n",
        "            targets = targets.reshape(-1)           \n",
        "\n",
        "            # compute output\n",
        "            outputs = model(inputs.float())\n",
        "            # loss = F.nll_loss(outputs, targets.long())\n",
        "            loss = criterion(outputs, targets.long())\n",
        "          \n",
        "            total_loss += loss.item()\n",
        "            n += 1\n",
        "\n",
        "            _, predicted = torch.max(outputs.detach(), 1)\n",
        "            # predicted = outputs.max(1, keepdim=True)[1]\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).cpu().sum()\n",
        "\n",
        "    avg_test_acc = 100. * correct.item() / total.item()\n",
        "    avg_loss = total_loss / n\n",
        "\n",
        "    return avg_test_acc, avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m4yecvK2x1LI",
        "colab": {}
      },
      "source": [
        "# load network\n",
        "print(\"loading module\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VoxNet()\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-gaeze-cGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "train_data = ModelNetDataset(data_file='drive/My Drive/Dataset/X_train.npy',\n",
        "                                    label_file='drive/My Drive/Dataset/y_train.npy',\n",
        "                                          transform=transforms.Compose([\n",
        "                                               toComplexRepr()\n",
        "                                           ])\n",
        "                                           )\n",
        "\n",
        "test_data1 = ModelNetDataset(data_file='drive/My Drive/Dataset/X_test.npy',\n",
        "                                    label_file='drive/My Drive/Dataset/y_test.npy',\n",
        "                                          transform=transforms.Compose([\n",
        "                                               toComplexRepr()\n",
        "                                           ])\n",
        "                                           ) \n",
        "\n",
        "# train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=4)\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True, num_workers=2)\n",
        "test_loader1 = DataLoader(test_data1, batch_size=8, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxIwCyHbB2oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_batch, labels = next(iter(train_loader))\n",
        "# print(train_batch.shape)\n",
        "\n",
        "# test_batch1, labels1 = next(iter(test_loader1))\n",
        "# print(test_batch1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHUxJV7hB8Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UtcqCMJ2xylc",
        "colab": {}
      },
      "source": [
        "start_epoch = 0\n",
        "best_acc = 0.\n",
        "n_iters = 10\n",
        "train_acc=[]\n",
        "train_loss=[]\n",
        "test1_acc=[]\n",
        "test1_loss=[]\n",
        "# test2_acc=[]\n",
        "# test2_loss=[]\n",
        "\n",
        "# set optimization methods\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, 0.8)\n",
        "\n",
        "for epoch in range(start_epoch, n_iters):\n",
        "    \n",
        "    print('Epoch: [%d/%d]' % (epoch+1, n_iters))\n",
        "    start = time.time()\n",
        "\n",
        "    # model.train()\n",
        "    avg_train_acc, avg_loss = train_model(train_loader, model, criterion, optimizer, device)\n",
        "    train_acc.append(avg_train_acc)\n",
        "    train_loss.append(avg_loss)\n",
        "    print(\"Train Accuracy:\", avg_train_acc)\n",
        "    print('Time taken: %.2f sec.' % (time.time() - start))\n",
        "    # scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    avg_test1_acc, avg_loss1 = test_model(test_loader1, model, criterion, optimizer, device)\n",
        "    test1_acc.append(avg_test1_acc)\n",
        "    test1_loss.append(avg_loss1)\n",
        "    print(\"Test Accuracy on Test1:\", avg_test1_acc)\n",
        "\n",
        "    # avg_test2_acc, avg_loss2 = test_model(test_loader2, model, criterion, optimizer, device)\n",
        "    # test2_acc.append(avg_test2_acc)\n",
        "    # test2_loss.append(avg_loss2)\n",
        "    # print(\"Test Accuracy on Test2:\", avg_test2_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzaL-MboBYT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(range(1, len(train_acc) + 1),train_acc, label='Train Accuracy')\n",
        "#plt.plot(range(1, len(test1_acc) + 1),test1_acc, label='Test1 Accuracy') \n",
        "plt.plot(range(1, len(test2_acc) + 1),test2_acc, label='Test2 Accuracy') \n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Accuracy') \n",
        "plt.legend(loc='best')\n",
        "plt.title('Train/Validation Accuracy vs Epochs for Voxnet') \n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(range(1, len(train_loss) + 1),train_loss, label='Train Loss')\n",
        "#plt.plot(range(1, len(test1_loss) + 1),test1_loss, label='Test1 Loss')\n",
        "plt.plot(range(1, len(test2_loss) + 1),test2_loss, label='Test2 Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Training/Validation Loss vs Epochs for Voxnet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDJM4j9rJD1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}